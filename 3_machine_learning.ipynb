{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Statistcs\n",
    "2. SVM model\n",
    "3. visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "import seaborn as sns\n",
    "from scipy.stats import levene, shapiro, ttest_ind\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, ParameterSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import itertools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess\n",
    "1. train test split\n",
    "2. Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "path = 'path'\n",
    "H_data = pd.read_csv(path + 'HighFeature.csv')\n",
    "L_data = pd.read_csv(path + 'LowFeature.csv')\n",
    "H_data['Label'] = 1\n",
    "L_data['Label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "XH_train, XH_test, yH_train, yH_test = train_test_split(H_data.drop(columns='Label'), H_data['Label'], test_size=0.3, random_state=1)\n",
    "XL_train, XL_test, yL_train, yL_test = train_test_split(L_data.drop(columns='Label'), L_data['Label'], test_size=0.3, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "- Check if variables are significant different in two groups\n",
    "1. shapiro (檢查是否為常態分布)\n",
    "2. Levene (檢查資料是否為相同變異數)\n",
    "3. two-tailed t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_feature = []\n",
    "p_values = []\n",
    "for feature in XH_train.columns:\n",
    "    sat, p_value_H = shapiro(XH_train[feature])\n",
    "    sat, p_value_L = shapiro(XL_train[feature])\n",
    "    if p_value_H>0.05 and p_value_L>0.05:\n",
    "        sat, p_value = levene(XH_train[feature], XL_train[feature])\n",
    "        if p_value > 0.05:\n",
    "            sat, p_value = ttest_ind(XH_train[feature], XL_train[feature], equal_var = True)\n",
    "            if p_value <0.05:\n",
    "                good_feature.append(feature)\n",
    "                p_values.append(p_value)\n",
    "\n",
    "print(dict(zip(good_feature, p_values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ParameterSampler\n",
    "param_grid={\"gamma\":[0.001, 0.01, 0.1, 1], \"C\":[0.01, 0.1, 1, 10, 100]}\n",
    "pam = ParameterSampler(param_grid, n_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "test_acc = []\n",
    "param_list = []\n",
    "\n",
    "XH_train, XH_test, yH_train, yH_test = train_test_split(H_data[['CH2_HbT_Trail_Feedback_Std_Diff', 'CH2_Oxy_Trail_Slope']], H_data['Label'], test_size=0.3, random_state=i)\n",
    "XL_train, XL_test, yL_train, yL_test = train_test_split(L_data[['CH2_HbT_Trail_Feedback_Std_Diff', 'CH2_Oxy_Trail_Slope']], L_data['Label'], test_size=0.3, random_state=i)\n",
    "X_train = pd.concat([XH_train, XL_train])\n",
    "X_test = pd.concat([XH_test, XL_test])\n",
    "y_train = pd.concat([yH_train, yL_train])\n",
    "y_test = pd.concat([yH_test, yL_test])\n",
    "\n",
    "stdd = StandardScaler()\n",
    "X_train_std = stdd.fit_transform(X_train)\n",
    "X_test_std = stdd.transform(X_test)\n",
    "\n",
    "param_grid={\"gamma\":[0.001, 0.01, 0.1, 1], \"C\":[0.01, 0.1, 1, 10, 100]}\n",
    "pam = ParameterSampler(param_grid, n_iter=20)\n",
    "for parameter in list(pam):\n",
    "    svc = SVC(kernel='rbf', **parameter)\n",
    "\n",
    "    svc = svc.fit(X_train_std, y_train)\n",
    "    y_predict = svc.predict(X_test_std)\n",
    "    y_predict_train = svc.predict(X_train_std)\n",
    "\n",
    "    if accuracy_score(y_train, y_predict_train)>0.8 and accuracy_score(y_test, y_predict)>0.70:\n",
    "        param_list.append(str(parameter))\n",
    "        train_acc.append(accuracy_score(y_train, y_predict_train))\n",
    "        test_acc.append(accuracy_score(y_test, y_predict))\n",
    "\n",
    "gan = pd.DataFrame()\n",
    "gan['param'] = param_list\n",
    "gan['train'] = train_acc\n",
    "gan['test'] = test_acc\n",
    "print(gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XH_train, XH_test, yH_train, yH_test = train_test_split(H_data[['CH2_HbT_Trail_Feedback_Std_Diff', 'CH2_Oxy_Trail_Slope']], H_data['Label'], test_size=0.3, random_state=987)\n",
    "XL_train, XL_test, yL_train, yL_test = train_test_split(L_data[['CH2_HbT_Trail_Feedback_Std_Diff', 'CH2_Oxy_Trail_Slope']], L_data['Label'], test_size=0.3, random_state=987)\n",
    "X_train = pd.concat([XH_train, XL_train])\n",
    "X_test = pd.concat([XH_test, XL_test])\n",
    "y_train = pd.concat([yH_train, yL_train])\n",
    "y_test = pd.concat([yH_test, yL_test])\n",
    "stdd = StandardScaler()\n",
    "X_train_std = stdd.fit_transform(X_train)\n",
    "X_test_std = stdd.transform(X_test)\n",
    "\n",
    "# param_grid={\"gamma\":[0.001, 0.01, 0.1, 1], \"C\":[0.01, 0.1, 1, 10, 100]}\n",
    "# pam = ParameterSampler(param_grid, n_iter=20)\n",
    "# for parameter in list(pam):\n",
    "\n",
    "model = SVC(kernel='rbf', gamma=1, C=10)\n",
    "\n",
    "clf = model.fit(X_train_std, y_train)\n",
    "y_predict = clf.predict(X_test_std)\n",
    "y_predict_train = clf.predict(X_train_std)\n",
    "# if accuracy_score(y_train, y_predict_train)>0.8 and accuracy_score(y_test, y_predict)>0.70:\n",
    "# print(i)\n",
    "# print(str(parameter))\n",
    "print(accuracy_score(y_train, y_predict_train))\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h = .02):\n",
    "    x_min, x_max = x.min() - 0.5, x.max() + 0.5\n",
    "    y_min, y_max = y.min() - 0.5, y.max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(ax, clf, xx, yy, **params ):\n",
    "    z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    #np.ravel():Return a contiguous flattened array\n",
    "    z = z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = accuracy_score(y_train, y_predict_train)\n",
    "test_accuracy = accuracy_score(y_test, y_predict)\n",
    "cm_light = mpl.colors.ListedColormap(['#FFA0A0', '#A0A0FF'])\n",
    "cm_dark = mpl.colors.ListedColormap(['r', 'b'])\n",
    "\n",
    "## Train\n",
    "fig, ax = plt.subplots()\n",
    "x0 = X_train_std[:, 0]\n",
    "x1 = X_train_std[:, 1]\n",
    "\n",
    "xx, yy = make_meshgrid(x0, x1)\n",
    "plot_contours(ax, clf, xx, yy, cmap = cm_light, alpha = 0.5)     #設PCA圖背景顏色\n",
    "\n",
    "ax.scatter(x0, x1, c = y_train, cmap = cm_dark, s = 100, edgecolors = 'k')\n",
    "patch0 = mpatches.Patch(color='#FF0000', label='Low')\n",
    "patch1 = mpatches.Patch(color='#0000FF', label='High')\n",
    "plt.legend(handles=[patch0, patch1])\n",
    "ax.set_xlabel('Standard Deviation Difference of $\\Delta$HbT (Task-Feedback)', fontsize = 12)\n",
    "ax.set_ylabel('Transition slope of $\\Delta$HbO$_2$ (Task)', fontsize = 12)\n",
    "ax.grid(True, linestyle = '-.')\n",
    "ax.set_title(f'Train Accuracy={train_accuracy:.3f}%', size = 15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#test\n",
    "fig, ax = plt.subplots()\n",
    "x2 = X_test_std[:, 0]\n",
    "x3 = X_test_std[:, 1]\n",
    "\n",
    "# xx, yy = make_meshgrid(x2, x3)\n",
    "plot_contours(ax, clf, xx, yy, cmap = cm_light, alpha = 0.5)     #設PCA圖背景顏色\n",
    "\n",
    "ax.scatter(x2, x3, c = y_test, cmap = cm_dark, s = 100, edgecolors = 'k')\n",
    "patch0 = mpatches.Patch(color='#FF0000', label='Low')\n",
    "patch1 = mpatches.Patch(color='#0000FF', label='High')\n",
    "plt.legend(handles=[patch0, patch1])\n",
    "ax.set_xlabel('Standard Deviation Difference of $\\Delta$HbT (Task-Feedback)', fontsize = 12)\n",
    "ax.set_ylabel('Transition slope of $\\Delta$HbO$_2$ (Task)', fontsize = 12)\n",
    "ax.grid(True, linestyle = '-.')\n",
    "ax.set_title(f'Test Accuracy={test_accuracy:.3f}%', size = 15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title, normalize = False, cmap = plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "        print('\\nNormalized confusion matrix:')\n",
    "    else:\n",
    "        print('\\nUnnormalized confusion matrix:')\n",
    "    print(cm)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(shrink = .92)     #使colorbar長度變為原來的92%\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, fontsize = 10)\n",
    "    plt.yticks(tick_marks, classes, rotation = 90, fontsize = 10)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment = 'center', color = 'white' if cm[i, j] > 0.5 else 'black')\n",
    "        #設定confusion matrix中數字顏色(過0.5變為黑色)   \n",
    "        plt.xlabel('Predicted label', size = 10)\n",
    "        plt.ylabel('True label', size = 10)\n",
    "        plt.tight_layout()     \n",
    "        #plt.tight_layout:自動調整繪圖區的大小及間距"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, clf.predict(X_test_std))    \n",
    "target = ['Low', 'High']\n",
    "\n",
    "plot_confusion_matrix(matrix, classes = target, title = 'Normalized confusion matrix', normalize = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_data = pd.concat([H_data, L_data], axis=0)\n",
    "All_data['Label'] = All_data['Label'].map({1:'High', 0:'Low'})\n",
    "feature = All_data['CH2_HbT_Trail_Feedback_Std_Diff']\n",
    "# feature = All_data['CH3_HbT_Trail_Feedback_Std_Diff']\n",
    "# feature = All_data['CH2_Oxy_Trail_Slope']\n",
    "# feature = All_data['CH3_Oxy_Trail_Slope']\n",
    "feature = (feature - feature.min())/(feature.max() - feature.min())\n",
    "label = All_data['Label']\n",
    "Data = pd.concat([feature, label], axis=1)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.grid(True, linestyle = '-.')\n",
    "sns.boxplot(data=Data, x='Label', y='CH2_HbT_Trail_Feedback_Std_Diff')\n",
    "# sns.boxplot(data=Data, x='Label', y='CH3_Oxy_Trail_Slope')\n",
    "plt.title('CH_2 Standard Deviation Difference of $\\Delta$ HbT (Task-Feedback)',fontsize=20) \n",
    "# plt.title('CH_3 Transition slope of $\\Delta$HbO$_2$ (Task)',fontsize=20) \n",
    "plt.xlabel('Score',fontsize=20)\n",
    "# plt.ylabel('$\\Delta$HbT ($\\mu$M)',fontsize=20)\n",
    "plt.ylabel('$\\Delta$HbO$_2$ ($\\mu$M)',fontsize=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
